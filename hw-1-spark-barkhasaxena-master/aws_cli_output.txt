maverick@Barkhas-MacBook-Pro hw-1-spark-barkhasaxena % make aws
mvn clean package
[INFO] Scanning for projects...
[INFO]
[INFO] -------------------------< cs6240:spark-demo >--------------------------
[INFO] Building spark-demo 1.0
[INFO] --------------------------------[ jar ]---------------------------------
[WARNING] The POM for commons-codec:commons-codec:jar:1.15-SNAPSHOT is missing, no dependency information available
[INFO]
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ spark-demo ---
[INFO] Deleting /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-demo ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO]
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ spark-demo ---
[INFO] Nothing to compile - all classes are up to date
[INFO]
[INFO] --- scala-maven-plugin:3.3.1:compile (default) @ spark-demo ---
[WARNING]  Expected all dependencies to require Scala version: 2.11.12
[WARNING]  cs6240:spark-demo:1.0 requires scala version: 2.11.12
[WARNING]  com.twitter:chill_2.11:0.8.4 requires scala version: 2.11.8
[WARNING] Multiple versions of scala libraries detected!
[INFO] /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/src/main/scala:-1: info: compiling
[INFO] Compiling 1 source files to /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/target/classes at 1643998735085
[INFO] prepare-compile in 0 s
[INFO] compile in 3 s
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-demo ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/src/test/resources
[INFO]
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ spark-demo ---
[INFO] No sources to compile
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ spark-demo ---
[INFO] No tests to run.
[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ spark-demo ---
[INFO] Building jar: /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/target/spark-demo-1.0.jar
[INFO]
[INFO] --- maven-shade-plugin:3.1.0:shade (default) @ spark-demo ---
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/target/spark-demo-1.0.jar with /Users/maverick/Documents/Courses/LSDP/git/hw-1-spark-barkhasaxena/target/spark-demo-1.0-shaded.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  5.634 s
[INFO] Finished at: 2022-02-04T13:18:58-05:00
[INFO] ------------------------------------------------------------------------
cp target/spark-demo-1.0.jar spark-demo.jar
aws s3 cp spark-demo.jar s3://barkha-lsdp
upload: ./spark-demo.jar to s3://barkha-lsdp/spark-demo.jar
aws s3 rm s3://barkha-lsdp/ --recursive --exclude "*" --include "output*"
aws emr create-cluster \
                --name "WordCount Spark Cluster" \
                --release-label emr-5.17.0 \
                --instance-groups '[{"InstanceCount":3,"InstanceGroupType":"CORE","InstanceType":"m4.large"},{"InstanceCount":1,"InstanceGroupType":"MASTER","InstanceType":"m4.large"}]' \
            --applications Name=Hadoop Name=Spark \
                --steps Type=CUSTOM_JAR,Name="Word Count",Jar="command-runner.jar",ActionOnFailure=TERMINATE_CLUSTER,Args=["spark-submit","--deploy-mode","cluster","--class","wc.WordCountMain","s3://barkha-lsdp/spark-demo.jar","s3://barkha-lsdp/input","s3://barkha-lsdp/output"] \
                --log-uri s3://barkha-lsdp/log \
                --use-default-roles \
                --enable-debugging \
                --auto-terminate
{
    "ClusterId": "**id-removed-for-git**",
    "ClusterArn": "arn:aws:elasticmapreduce:us-east-1:273516045322:cluster/j-CQ7WU4EBAZ8K"
}
